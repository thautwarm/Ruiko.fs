# optional: use custom lexer 
deflexer from "path/lexer.fs"


# define String   : read definition of `string`       from $RUIKO_HOME/std.ruiko.
# define Name     : read definition of `unicode_name` from $RUIKO_HOME/std.ruiko.
# define Space    : read definition of `space`        from $RUIKO_HOME/std.ruiko.
# define Comments : read definition of `comments`     from $RUIKO_HOME/cpp.ruiko.

import 
    std.{
        string       => String 
        unicode_name => Name
        space        => Space 
    },    
    cpp.{
        comments     => Comments
    }


# define tokenizer and literal parser
mytoken -> 
    # multi-cases
    | R'<regex>'
    | '<lteral>'
    | ~R'<regex
    >'
    | ~'<literal>'

    cast # cast token nizer
    
    at '{' mytoken '}' # optional. context sensitive specification
    
    as K # optional. custom prefix

# define combined parser
myparser =>
    | mytoken as symbol1 '{' '}' 
      # binding a term as `symbol1` into context in current grammar case.  
      constraint
        # optional
        # TODO: require turning complete ruiko lang here. 
        # a predicate, to give whether to accept parsed result of current grammar case.

    | 'def' Name as symbol1 '(' argList ')' ';';  # binding a term as `symbol1`...
    where 
        # define some local macro
        argList = Name (',' Name)*
    
    when
        # TODO: require turning complete ruiko lang here. 
        # a predicate, to give whether to use this parser in current context;
    
    

XML =>
    | '<' name '/' '>'

    | tagHead<name> XML* tagEnd<name>
      constraint
        head as Token(htoken)
        tail as Token(ttoken)
        htoken.string.Equals(ttoken.string) 

    | text 
    where 
        tagHead x = '<' x as head '>'
        tagEnd  x = '<' '/' x as tail '>'
        text      =  _ + 
        # _ indicates a wild case, which means any tokenizer.
        # _<type> means a any tokenizer with name `type`.




    






